{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "import os\n",
    "#import cv2 \n",
    "import numpy as np \n",
    "import math \n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_celeb = np.load('/media/ml/Data Disk/upscaling/X_train64.npy')\n",
    "Y_celeb = np.load('/media/ml/Data Disk/upscaling/Y_train64.npy')\n",
    "\n",
    "X_tiny = np.load('/media/ml/Data Disk/upscaling/tinyface/X_train.npy')\n",
    "Y_tiny = np.load('/media/ml/Data Disk/upscaling/tinyface/Y_train.npy')\n",
    "\n",
    "#testx = np.load('')\n",
    "#testy = np.load('')\n",
    "train_size_celeb = 202599\n",
    "num_classes_celeb = 10177\n",
    "num_classes_tiny = 2570\n",
    "file_size = 64\n",
    "\n",
    "X_celeb = (X_celeb[:,:,:,:]/255).astype('float16')\n",
    "X_tiny = (X_tiny[:,:,:,:]/255).astype('float16')\n",
    "\n",
    "\n",
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y\n",
    "  \n",
    "Y_celeb = convert_to_one_hot(Y_celeb, num_classes_celeb).T  \n",
    "Y_tiny = convert_to_one_hot(Y_tiny, num_classes_tiny).T  \n",
    "\n",
    "\n",
    "print(X_celeb.shape, Y_celeb.shape)\n",
    "print(X_tiny.shape, Y_tiny.shape)\n",
    "\n",
    "#print(X_test.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def srcnn(X, num_op):\n",
    "\n",
    "    gen1 = tf.layers.conv2d(X, 64, 9, 1, padding = 'valid')\n",
    "    A1 = tf.nn.relu(gen1)    \n",
    "    P1 = tf.nn.max_pool(A1, ksize = [1,2,2,1], strides = [1,2,2,1], padding = 'SAME')\n",
    "    \n",
    "    gen2 = tf.layers.conv2d(P1, 32, 3, 1, padding = 'SAME')\n",
    "    A2 = tf.nn.relu(gen2)    \n",
    "    P2 = tf.nn.max_pool(A2, ksize = [1,4,4,1], strides = [1,4,4,1], padding = 'SAME')\n",
    "\n",
    "    res_in = P2\n",
    "    rc1 = tf.layers.conv2d(res_in, 16, 3, 1, padding = 'SAME')\n",
    "    r2 = tf.layers.conv2d(rc1, 16, 1, 1, padding = 'SAME')\n",
    "    r3 = tf.layers.conv2d(r2, 16, 1, 1, padding = 'SAME')\n",
    "    r4 = tf.layers.conv2d(r3, 16, 1, 1, padding = 'SAME')\n",
    "    r5 = tf.layers.conv2d(r4, 16, 1, 1, padding = 'SAME')\n",
    "    r6 = tf.layers.conv2d(r5, 16, 1, 1, padding = 'SAME')\n",
    "    r7 = tf.layers.conv2d(r6, 16, 1, 1, padding = 'SAME')\n",
    "    res_out = tf.keras.layers.concatenate([res_in, r7])\n",
    "    res_out = tf.nn.relu(res_out)   \n",
    "\n",
    "    res_in = res_out\n",
    "    rc1 = tf.layers.conv2d(res_in, 16, 3, 1, padding = 'SAME')\n",
    "    r2 = tf.layers.conv2d(rc1, 16, 1, 1, padding = 'SAME')\n",
    "    r3 = tf.layers.conv2d(r2, 16, 1, 1, padding = 'SAME')\n",
    "    r4 = tf.layers.conv2d(r3, 16, 1, 1, padding = 'SAME')\n",
    "    r5 = tf.layers.conv2d(r4, 16, 1, 1, padding = 'SAME')\n",
    "    r6 = tf.layers.conv2d(r5, 16, 1, 1, padding = 'SAME')\n",
    "    r7 = tf.layers.conv2d(r6, 16, 1, 1, padding = 'SAME')\n",
    "    res_out = tf.keras.layers.concatenate([res_in, r7])\n",
    "    res_out = tf.nn.relu(res_out)   \n",
    "\n",
    "    res_in = res_out\n",
    "    rc1 = tf.layers.conv2d(res_in, 16, 3, 1, padding = 'SAME')\n",
    "    r2 = tf.layers.conv2d(rc1, 16, 1, 1, padding = 'SAME')\n",
    "    r3 = tf.layers.conv2d(r2, 16, 1, 1, padding = 'SAME')\n",
    "    r4 = tf.layers.conv2d(r3, 16, 1, 1, padding = 'SAME')\n",
    "    r5 = tf.layers.conv2d(r4, 16, 1, 1, padding = 'SAME')\n",
    "    r6 = tf.layers.conv2d(r5, 16, 1, 1, padding = 'SAME')\n",
    "    r7 = tf.layers.conv2d(r6, 16, 1, 1, padding = 'SAME')\n",
    "    res_out = tf.keras.layers.concatenate([res_in, r7])\n",
    "    res_out = tf.nn.relu(res_out)    \n",
    "    \n",
    "    gen3 = tf.layers.conv2d(res_out, 3, 5, 1, padding = 'SAME')\n",
    "    \n",
    "    P3 = tf.nn.relu(gen3)  \n",
    "    \n",
    "    \n",
    "    P_fl = tf.contrib.layers.flatten(P3)\n",
    "    fc = tf.contrib.layers.fully_connected(P_fl, num_op, activation_fn = None)\n",
    "    \n",
    "    return P3, fc\n",
    "\n",
    "def inception(X, num_op):\n",
    "\n",
    "    A1 = tf.nn.relu(X)    \n",
    "    \n",
    "    gen11 = tf.layers.conv2d(A1, 64, 1, 1, padding = 'SAME')\n",
    "\n",
    "    gen21 = tf.layers.conv2d(A1, 32, 1, 1, padding = 'SAME')\n",
    "    gen22 = tf.layers.conv2d(gen21, 16, 3, 1, padding = 'SAME')\n",
    "\n",
    "    gen31 = tf.layers.conv2d(A1, 16, 1, 1, padding = 'SAME')\n",
    "    gen32 = tf.layers.conv2d(gen31, 32, 3, 1, padding = 'SAME')\n",
    "    gen33 = tf.layers.conv2d(gen32, 64, 3, 1, padding = 'SAME')\n",
    "\n",
    "    l4 = tf.keras.layers.concatenate([gen11, gen22, gen33])\n",
    "    l5 = tf.keras.layers.concatenate([l4, A1])\n",
    "    \n",
    "    A6 = tf.nn.relu(l5)    \n",
    "    \n",
    "    P_fl = tf.contrib.layers.flatten(A6)\n",
    "    fc = tf.contrib.layers.fully_connected(P_fl, num_op, activation_fn = None)\n",
    "    \n",
    "    return fc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "imported_meta = tf.train.import_meta_graph(\"/media/ml/Data Disk/upscaling/model/model.ckpt.meta\")\n",
    "\n",
    "(m, n_H0, n_W0, n_C0) = X_celeb.shape  \n",
    "(m1, n_H1, n_W1, n_C1) = X_tiny.shape             \n",
    "n_y = Y_celeb.shape[1]       \n",
    "n_y1 = Y_tiny.shape[1]                            \n",
    "\n",
    "costs = []                                                            \n",
    "t1 = 0\n",
    "t2 = 0\n",
    "learning_rate = 0.0001\n",
    "num_epochs = 500\n",
    "\n",
    "X_c = tf.placeholder(tf.float32, [None, n_H0, n_W0, n_C0], name = 'X_c')\n",
    "Y_c = tf.placeholder(tf.float32, [None, n_y], name = 'Y_c')\n",
    "X_t = tf.placeholder(tf.float32, [None, n_H1, n_W1, n_C1], name = 'X_t')\n",
    "Y_t = tf.placeholder(tf.float32, [None, n_y1], name = 'Y_t')\n",
    "\n",
    "Pc, Z1c = srcnn(X_c, num_classes_celeb)\n",
    "Z2c = inception(Pc, num_classes_celeb)\n",
    "\n",
    "Pt, Z1t = srcnn(X_t, num_classes_tiny)\n",
    "Z2t = inception(Pt, num_classes_tiny)\n",
    "\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    imported_meta.restore(sess, tf.train.latest_checkpoint('/media/ml/Data Disk/upscaling/model'))\n",
    "    print(\"restored\")\n",
    "    predict_op = tf.argmax(Z2c, 1)\n",
    "    correct_prediction = tf.equal(predict_op, tf.argmax(Y_c, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    train_accuracy = accuracy.eval({X_c: X_celeb, Y_c: Y_celeb, X_t: X_tiny, Y_t: Y_tiny})\n",
    "    #, X_t: X_tiny, Y_t:Y_tiny\n",
    "    print(\"Train Accuracy:\", train_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-6a2f1d1c3c34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mArgumentParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Up-Scales an image using Image Super Resolution Model\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
